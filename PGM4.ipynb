{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89fe845e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data:\n",
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "Shape of test data:\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n",
      "Epoch 1/15\n",
      "1250/1250 - 5s - loss: 1.8288 - accuracy: 0.3391 - val_loss: 1.7059 - val_accuracy: 0.3912 - 5s/epoch - 4ms/step\n",
      "Epoch 2/15\n",
      "1250/1250 - 5s - loss: 1.6572 - accuracy: 0.4079 - val_loss: 1.6404 - val_accuracy: 0.4168 - 5s/epoch - 4ms/step\n",
      "Epoch 3/15\n",
      "1250/1250 - 5s - loss: 1.5882 - accuracy: 0.4307 - val_loss: 1.6073 - val_accuracy: 0.4345 - 5s/epoch - 4ms/step\n",
      "Epoch 4/15\n",
      "1250/1250 - 5s - loss: 1.5420 - accuracy: 0.4481 - val_loss: 1.5631 - val_accuracy: 0.4475 - 5s/epoch - 4ms/step\n",
      "Epoch 5/15\n",
      "1250/1250 - 5s - loss: 1.5070 - accuracy: 0.4597 - val_loss: 1.5498 - val_accuracy: 0.4524 - 5s/epoch - 4ms/step\n",
      "Epoch 6/15\n",
      "1250/1250 - 5s - loss: 1.4749 - accuracy: 0.4699 - val_loss: 1.5699 - val_accuracy: 0.4495 - 5s/epoch - 4ms/step\n",
      "Epoch 7/15\n",
      "1250/1250 - 5s - loss: 1.4493 - accuracy: 0.4807 - val_loss: 1.5734 - val_accuracy: 0.4445 - 5s/epoch - 4ms/step\n",
      "Epoch 8/15\n",
      "1250/1250 - 5s - loss: 1.4294 - accuracy: 0.4897 - val_loss: 1.5530 - val_accuracy: 0.4678 - 5s/epoch - 4ms/step\n",
      "Epoch 9/15\n",
      "1250/1250 - 5s - loss: 1.4102 - accuracy: 0.4948 - val_loss: 1.5362 - val_accuracy: 0.4657 - 5s/epoch - 4ms/step\n",
      "Epoch 10/15\n",
      "1250/1250 - 5s - loss: 1.3870 - accuracy: 0.5035 - val_loss: 1.5101 - val_accuracy: 0.4650 - 5s/epoch - 4ms/step\n",
      "Epoch 11/15\n",
      "1250/1250 - 5s - loss: 1.3674 - accuracy: 0.5074 - val_loss: 1.5747 - val_accuracy: 0.4639 - 5s/epoch - 4ms/step\n",
      "Epoch 12/15\n",
      "1250/1250 - 5s - loss: 1.3498 - accuracy: 0.5150 - val_loss: 1.4898 - val_accuracy: 0.4797 - 5s/epoch - 4ms/step\n",
      "Epoch 13/15\n",
      "1250/1250 - 5s - loss: 1.3338 - accuracy: 0.5214 - val_loss: 1.4742 - val_accuracy: 0.4835 - 5s/epoch - 4ms/step\n",
      "Epoch 14/15\n",
      "1250/1250 - 5s - loss: 1.3151 - accuracy: 0.5287 - val_loss: 1.4910 - val_accuracy: 0.4776 - 5s/epoch - 4ms/step\n",
      "Epoch 15/15\n",
      "1250/1250 - 5s - loss: 1.2994 - accuracy: 0.5353 - val_loss: 1.5321 - val_accuracy: 0.4675 - 5s/epoch - 4ms/step\n",
      "['loss', 'accuracy']\n",
      "[1.5194860696792603, 0.4715999960899353]\n"
     ]
    }
   ],
   "source": [
    "# WITH XAVIER INITIALIZATION----Ask students to analyse various other parameter initialization techniques also through \n",
    "# #https://keras.io/api/layers/initializers/\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils.np_utils import to_categorical   \n",
    "\n",
    "tf.keras.initializers.GlorotUniform(seed=None)\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print(\"Shape of training data:\")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(\"Shape of test data:\")\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)`\n",
    "\n",
    "\n",
    "# Transform label indices to one-hot encoded vectors\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Transform images from (32,32,3) to 3072-dimensional vectors (32*32*3)\n",
    "\n",
    "X_train = np.reshape(X_train,(50000,3072))\n",
    "X_test = np.reshape(X_test,(10000,3072))\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Normalization of pixel values (to [0-1] range)\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "modelMLP_Xavier = Sequential()\n",
    "modelMLP_Xavier.add(Dense(256, activation='relu', input_dim=3072))\n",
    "modelMLP_Xavier.add(Dense(256, activation='relu'))\n",
    "modelMLP_Xavier.add(Dense(10, activation='softmax'))\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "modelMLP_Xavier.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "historyMLP_Xavier = modelMLP_Xavier.fit(X_train,y_train, epochs=15, batch_size=32, verbose=2, validation_split=0.2)\n",
    "scoreMLP_Xavier = modelMLP_Xavier.evaluate(X_test, y_test, batch_size=128, verbose=0)\n",
    "print(modelMLP_Xavier.metrics_names)\n",
    "print(scoreMLP_Xavier)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485db9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://keras.io/api/layers/initializers/\n",
    "#https://pyimagesearch.com/2021/05/06/understanding-weight-initialization-for-neural-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a0d3b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data:\n",
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "Shape of test data:\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n",
      "Epoch 1/15\n",
      "1250/1250 - 6s - loss: 1.9653 - accuracy: 0.2727 - val_loss: 1.8383 - val_accuracy: 0.3197 - 6s/epoch - 5ms/step\n",
      "Epoch 2/15\n",
      "1250/1250 - 5s - loss: 1.8477 - accuracy: 0.3255 - val_loss: 1.7547 - val_accuracy: 0.3752 - 5s/epoch - 4ms/step\n",
      "Epoch 3/15\n",
      "1250/1250 - 5s - loss: 1.7902 - accuracy: 0.3498 - val_loss: 1.7285 - val_accuracy: 0.3944 - 5s/epoch - 4ms/step\n",
      "Epoch 4/15\n",
      "1250/1250 - 5s - loss: 1.7588 - accuracy: 0.3623 - val_loss: 1.7199 - val_accuracy: 0.3790 - 5s/epoch - 4ms/step\n",
      "Epoch 5/15\n",
      "1250/1250 - 5s - loss: 1.7279 - accuracy: 0.3744 - val_loss: 1.6798 - val_accuracy: 0.4068 - 5s/epoch - 4ms/step\n",
      "Epoch 6/15\n",
      "1250/1250 - 5s - loss: 1.7054 - accuracy: 0.3843 - val_loss: 1.6728 - val_accuracy: 0.4068 - 5s/epoch - 4ms/step\n",
      "Epoch 7/15\n",
      "1250/1250 - 5s - loss: 1.6874 - accuracy: 0.3904 - val_loss: 1.6209 - val_accuracy: 0.4251 - 5s/epoch - 4ms/step\n",
      "Epoch 8/15\n",
      "1250/1250 - 5s - loss: 1.6671 - accuracy: 0.3944 - val_loss: 1.6659 - val_accuracy: 0.4144 - 5s/epoch - 4ms/step\n",
      "Epoch 9/15\n",
      "1250/1250 - 5s - loss: 1.6577 - accuracy: 0.4009 - val_loss: 1.6079 - val_accuracy: 0.4315 - 5s/epoch - 4ms/step\n",
      "Epoch 10/15\n",
      "1250/1250 - 5s - loss: 1.6527 - accuracy: 0.4012 - val_loss: 1.5824 - val_accuracy: 0.4432 - 5s/epoch - 4ms/step\n",
      "Epoch 11/15\n",
      "1250/1250 - 5s - loss: 1.6349 - accuracy: 0.4096 - val_loss: 1.6357 - val_accuracy: 0.4146 - 5s/epoch - 4ms/step\n",
      "Epoch 12/15\n",
      "1250/1250 - 5s - loss: 1.6235 - accuracy: 0.4135 - val_loss: 1.6196 - val_accuracy: 0.4144 - 5s/epoch - 4ms/step\n",
      "Epoch 13/15\n",
      "1250/1250 - 5s - loss: 1.6145 - accuracy: 0.4146 - val_loss: 1.6215 - val_accuracy: 0.4266 - 5s/epoch - 4ms/step\n",
      "Epoch 14/15\n",
      "1250/1250 - 5s - loss: 1.6055 - accuracy: 0.4193 - val_loss: 1.5677 - val_accuracy: 0.4449 - 5s/epoch - 4ms/step\n",
      "Epoch 15/15\n",
      "1250/1250 - 5s - loss: 1.5994 - accuracy: 0.4238 - val_loss: 1.6197 - val_accuracy: 0.4216 - 5s/epoch - 4ms/step\n",
      "['loss', 'accuracy']\n",
      "[1.6038689613342285, 0.43149998784065247]\n"
     ]
    }
   ],
   "source": [
    "# with droput layer implemented----will give accuracy change when more layer are there..if only 3 layers, not much difference in accuracy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print(\"Shape of training data:\")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(\"Shape of test data:\")\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "# Transform label indices to one-hot encoded vectors\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Transform images from (32,32,3) to 3072-dimensional vectors (32*32*3)\n",
    "\n",
    "X_train = np.reshape(X_train,(50000,3072))\n",
    "X_test = np.reshape(X_test,(10000,3072))\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Normalization of pixel values (to [0-1] range)\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "modelMLP_Dropout = Sequential()\n",
    "modelMLP_Dropout.add(Dense(256, activation='relu', input_dim=3072))\n",
    "\n",
    "modelMLP_Dropout.add(Dropout(0.25))\n",
    "\n",
    "modelMLP_Dropout.add(Dense(256, activation='relu'))\n",
    "modelMLP_Dropout.add(Dense(10, activation='softmax'))\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "modelMLP_Dropout.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "historyMLP_Dropout = modelMLP_Dropout.fit(X_train,y_train, epochs=15, batch_size=32, verbose=2, validation_split=0.2)\n",
    "scoreMLP_Dropout = modelMLP_Dropout.evaluate(X_test, y_test, batch_size=128, verbose=0)\n",
    "print(modelMLP_Dropout.metrics_names)\n",
    "print(scoreMLP_Dropout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2345e52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data:\n",
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "Shape of test data:\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n",
      "Epoch 1/15\n",
      "1250/1250 - 5s - loss: 1.7126 - accuracy: 0.3946 - val_loss: 2.0956 - val_accuracy: 0.2893 - 5s/epoch - 4ms/step\n",
      "Epoch 2/15\n",
      "1250/1250 - 5s - loss: 1.5511 - accuracy: 0.4465 - val_loss: 1.6880 - val_accuracy: 0.4029 - 5s/epoch - 4ms/step\n",
      "Epoch 3/15\n",
      "1250/1250 - 5s - loss: 1.4966 - accuracy: 0.4680 - val_loss: 1.7048 - val_accuracy: 0.3959 - 5s/epoch - 4ms/step\n",
      "Epoch 4/15\n",
      "1250/1250 - 5s - loss: 1.4485 - accuracy: 0.4853 - val_loss: 1.5769 - val_accuracy: 0.4542 - 5s/epoch - 4ms/step\n",
      "Epoch 5/15\n",
      "1250/1250 - 5s - loss: 1.4016 - accuracy: 0.5004 - val_loss: 1.7064 - val_accuracy: 0.4058 - 5s/epoch - 4ms/step\n",
      "Epoch 6/15\n",
      "1250/1250 - 5s - loss: 1.3616 - accuracy: 0.5150 - val_loss: 2.1046 - val_accuracy: 0.4037 - 5s/epoch - 4ms/step\n",
      "Epoch 7/15\n",
      "1250/1250 - 5s - loss: 1.3353 - accuracy: 0.5245 - val_loss: 1.5116 - val_accuracy: 0.4726 - 5s/epoch - 4ms/step\n",
      "Epoch 8/15\n",
      "1250/1250 - 6s - loss: 1.3051 - accuracy: 0.5372 - val_loss: 1.6001 - val_accuracy: 0.4414 - 6s/epoch - 5ms/step\n",
      "Epoch 9/15\n",
      "1250/1250 - 7s - loss: 1.2799 - accuracy: 0.5448 - val_loss: 1.6209 - val_accuracy: 0.4402 - 7s/epoch - 5ms/step\n",
      "Epoch 10/15\n",
      "1250/1250 - 6s - loss: 1.2587 - accuracy: 0.5503 - val_loss: 1.7122 - val_accuracy: 0.4374 - 6s/epoch - 5ms/step\n",
      "Epoch 11/15\n",
      "1250/1250 - 6s - loss: 1.2351 - accuracy: 0.5611 - val_loss: 1.5362 - val_accuracy: 0.4840 - 6s/epoch - 5ms/step\n",
      "Epoch 12/15\n",
      "1250/1250 - 6s - loss: 1.2178 - accuracy: 0.5668 - val_loss: 1.5971 - val_accuracy: 0.4608 - 6s/epoch - 5ms/step\n",
      "Epoch 13/15\n",
      "1250/1250 - 5s - loss: 1.2064 - accuracy: 0.5715 - val_loss: 1.5326 - val_accuracy: 0.4766 - 5s/epoch - 4ms/step\n",
      "Epoch 14/15\n",
      "1250/1250 - 6s - loss: 1.1845 - accuracy: 0.5774 - val_loss: 1.5115 - val_accuracy: 0.4866 - 6s/epoch - 4ms/step\n",
      "Epoch 15/15\n",
      "1250/1250 - 6s - loss: 1.1722 - accuracy: 0.5836 - val_loss: 1.5102 - val_accuracy: 0.4862 - 6s/epoch - 5ms/step\n",
      "['loss', 'accuracy']\n",
      "[1.4789140224456787, 0.48980000615119934]\n"
     ]
    }
   ],
   "source": [
    "# with batch normalisation\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print(\"Shape of training data:\")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(\"Shape of test data:\")\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "# Transform label indices to one-hot encoded vectors\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Transform images from (32,32,3) to 3072-dimensional vectors (32*32*3)\n",
    "\n",
    "X_train = np.reshape(X_train,(50000,3072))\n",
    "X_test = np.reshape(X_test,(10000,3072))\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Normalization of pixel values (to [0-1] range)\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "modelMLP_BatchNorm = Sequential()\n",
    "modelMLP_BatchNorm.add(Dense(256, activation='relu', input_dim=3072))\n",
    "\n",
    "\n",
    "modelMLP_BatchNorm.add(BatchNormalization())\n",
    "\n",
    "modelMLP_BatchNorm.add(Dense(256, activation='relu'))\n",
    "modelMLP_BatchNorm.add(Dense(10, activation='softmax'))\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "modelMLP_BatchNorm.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "historyMLP_BatchNorm = modelMLP_BatchNorm.fit(X_train,y_train, epochs=15, batch_size=32, verbose=2, validation_split=0.2)\n",
    "scoreMLP_BatchNorm = modelMLP_BatchNorm.evaluate(X_test, y_test, batch_size=128, verbose=0)\n",
    "print(modelMLP_BatchNorm.metrics_names)\n",
    "print(scoreMLP_BatchNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80c711c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BatchNormalization' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4980\\579743503.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodelMLP_BatchNorm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodelMLP_BatchNorm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3072\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodelMLP_BatchNorm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BatchNormalization' is not defined"
     ]
    }
   ],
   "source": [
    "modelMLP_BatchNorm = Sequential()\n",
    "modelMLP_BatchNorm.add(Dense(256, activation='relu', input_dim=3072))\n",
    "modelMLP_BatchNorm.add(BatchNormalization())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35f08b21",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy._DTypeMeta' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15332\\571303353.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\cv2\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m \u001b[0mbootstrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\cv2\\__init__.py\u001b[0m in \u001b[0;36mbootstrap\u001b[1;34m()\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msubmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m__collect_extra_submodules\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEBUG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0m__load_extra_py_code_for_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cv2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Extra Python code for\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"is loaded\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\cv2\\__init__.py\u001b[0m in \u001b[0;36m__load_extra_py_code_for_module\u001b[1;34m(base, name, enable_debug_print)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mnative_module\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mpy_module\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0menable_debug_print\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\cv2\\typing\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNumpyVersion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;34m\"1.20.0\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m     \u001b[0mNumPyArrayGeneric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtyping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mNumPyArrayGeneric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy._DTypeMeta' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76e13dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\jinav\\anaconda3\\lib\\site-packages (1.25.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\jinav\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\jinav\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\jinav\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\jinav\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\jinav\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\jinav\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eeccf811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1817757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac43307",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
